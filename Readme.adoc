= PI_sample_duration

image::https://img.shields.io/:license-Apache%202.0-blue.svg[link=https://opensource.org/licenses/Apache-2.0]
image:https://travis-ci.org/eurobench/pi_python_duration.svg?branch=master["Build Status", link="https://travis-ci.org/eurobench/pi_python_duration"]

Copyright Tecnalia 2020

This is an example of Performance Indicator implemented in python.
It is prepared to be used within the Eurobench Benchmarking Software.

`pi_sample_duration` basically measures the duration of an experiment, by reading a unique `csv file` containing a `timestamp` column, and returns as PI values the difference between the timestamps of the last and first line recorded.

Requires the following packages (install with `apt-get`): `python3`, `python3-venv` .

And then run the following commands:

== Installation

[source, shell]
----
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r src/pi_sample_duration/requirements.txt
python src/pi_sample_duration/setup.py develop
----

== Usage

[source, shell]
----
./run_pi test_data/input/data_in.csv out_folder
----

We assume `out_folder` exists.

== Docker management

=== Docker image generation

Run the following command in order to create the docker image for this PI:

[source, shell]
----
docker build . -t pi_sample_duration
----

=== Launch the docker image

Assuming the folder `test_data/input/` contains the input data, and that the directory `out_folder/` is created, and will contain the PI output:

[source, shell]
----
docker run --rm -v $PWD/test_data/input:/in -v $PWD/out_folder:/out pi_sample_duration ./run_pi /in/data_in.csv /out
----

---

image::http://eurobench2020.eu/wp-content/uploads/2018/06/cropped-logoweb.png["eurobench logo",width=200]
Supported by Eurobench - the European robotic platform for bipedal locomotion benchmarking.
More information: http://eurobench2020.eu/[eurobench2020.eu]



image::http://eurobench2020.eu/wp-content/uploads/2018/02/euflag.png["euflag",role=left,width=100]
This project has received funding from the European Unionâ€™s Horizon 2020
research and innovation programme under grant agreement no. No 779963.